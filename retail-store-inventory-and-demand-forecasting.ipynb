{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efd4054f",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-05-31T17:50:37.732871Z",
     "iopub.status.busy": "2025-05-31T17:50:37.731087Z",
     "iopub.status.idle": "2025-05-31T17:50:39.868610Z",
     "shell.execute_reply": "2025-05-31T17:50:39.867547Z"
    },
    "papermill": {
     "duration": 2.148232,
     "end_time": "2025-05-31T17:50:39.870423",
     "exception": false,
     "start_time": "2025-05-31T17:50:37.722191",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/retail-store-inventory-and-demand-forecasting/sales_data.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a68ba9",
   "metadata": {
    "papermill": {
     "duration": 0.003885,
     "end_time": "2025-05-31T17:50:39.879109",
     "exception": false,
     "start_time": "2025-05-31T17:50:39.875224",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **Preliminary Data Cleaning Hypotheses**\n",
    "\n",
    "### **1. Missing Data & Integrity Checks**\n",
    "- **Null Values**:  \n",
    "  - Columns like `Weather Condition`, `Competitor Pricing`, and `Discount` may contain missing data.  \n",
    "  - **Action**: Impute using forward-fill or median values based on `Category`/`Region`.  \n",
    "- **Inventory-Sales Mismatch**:  \n",
    "  - If `Units Sold` > `Inventory Level`, data is invalid (sales cannot exceed stock).  \n",
    "  - **Action**: Flag/remove such records.  \n",
    "\n",
    "### **2. Temporal & Categorical Issues**\n",
    "- **Date Gaps**:  \n",
    "  - Check for missing dates (e.g., store closures during `Epidemic=1`).  \n",
    "  - **Action**: Resample time series and forward-fill static features (e.g., `Store ID`).  \n",
    "- **Categorical Consistency**:  \n",
    "  - `Category` or `Region` may have typos (e.g., \"Electronics\" vs. \"Eletronics\").  \n",
    "  - **Action**: Standardize labels using fuzzy matching.  \n",
    "\n",
    "### **3. Outliers & Anomalies**\n",
    "- **Demand Spikes**:  \n",
    "  - Extreme `Units Sold` during `Promotion=1` or `Epidemic=1`.  \n",
    "  - **Action**: Winsorize or cap values at 99th percentile.  \n",
    "- **Negative Inventory**:  \n",
    "  - `Inventory Level` < 0 suggests data entry errors.  \n",
    "  - **Action**: Set to zero or treat as missing.  \n",
    "\n",
    "### **4. Feature Engineering Ideas**\n",
    "- **Time Features**:  \n",
    "  - Derive `Day_of_week`, `Is_holiday`, and `Lag_7_Demand` from `Date`.  \n",
    "- **Competitor Impact**:  \n",
    "  - Create `Price_ratio = Price / Competitor Pricing` to measure relative affordability.  \n",
    "- **Stockout Risk**:  \n",
    "  - `Stock_coverage = Inventory Level / (7-day avg Units Sold)`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5be6eae6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-31T17:50:39.887924Z",
     "iopub.status.busy": "2025-05-31T17:50:39.887504Z",
     "iopub.status.idle": "2025-05-31T17:50:39.893484Z",
     "shell.execute_reply": "2025-05-31T17:50:39.892381Z"
    },
    "papermill": {
     "duration": 0.011376,
     "end_time": "2025-05-31T17:50:39.895108",
     "exception": false,
     "start_time": "2025-05-31T17:50:39.883732",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Imports and Configuration\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "DATA_PATH = Path('/kaggle/input/retail-store-inventory-and-demand-forecasting/sales_data.csv')\n",
    "CHUNKSIZE = 50_000\n",
    "DATE_COL = 'Date'\n",
    "\n",
    "# Optimized dtypes\n",
    "DTYPES = {\n",
    "    'Store ID': 'category',\n",
    "    'Product ID': 'category',\n",
    "    'Category': 'category',\n",
    "    'Region': 'category',\n",
    "    'Inventory Level': 'uint16',\n",
    "    'Units Sold': 'uint16',\n",
    "    'Units Ordered': 'uint16',\n",
    "    'Price': 'float32',\n",
    "    'Discount': 'float32',\n",
    "    'Weather Condition': 'category',\n",
    "    'Promotion': 'bool',\n",
    "    'Competitor Pricing': 'float32',\n",
    "    'Seasonality': 'category',\n",
    "    'Epidemic': 'bool',\n",
    "    'Demand': 'uint16'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a03dbe81",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-31T17:50:39.901558Z",
     "iopub.status.busy": "2025-05-31T17:50:39.901227Z",
     "iopub.status.idle": "2025-05-31T17:50:39.914192Z",
     "shell.execute_reply": "2025-05-31T17:50:39.913394Z"
    },
    "papermill": {
     "duration": 0.017942,
     "end_time": "2025-05-31T17:50:39.915685",
     "exception": false,
     "start_time": "2025-05-31T17:50:39.897743",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Data Import Function with Row Tracking\n",
    "def import_retail_data():\n",
    "    chunks = []\n",
    "    error_log = []\n",
    "    stats = {\n",
    "        'total_rows': 0,\n",
    "        'rows_dropped': {\n",
    "            'date_parsing': 0,\n",
    "            'inventory_adjustment': 0,\n",
    "            'sales_adjustment': 0,\n",
    "            'dtype_conversion': 0,\n",
    "            'chunk_failures': 0\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        with pd.read_csv(\n",
    "            DATA_PATH,\n",
    "            chunksize=CHUNKSIZE,\n",
    "            dtype=DTYPES,\n",
    "            parse_dates=[DATE_COL],\n",
    "            on_bad_lines='warn',\n",
    "            encoding='utf-8'\n",
    "        ) as reader:\n",
    "            \n",
    "            for chunk_idx, chunk in enumerate(reader):\n",
    "                stats['total_rows'] += len(chunk)\n",
    "                try:\n",
    "                    # Validate required columns\n",
    "                    required_cols = set(DTYPES.keys())\n",
    "                    missing_cols = required_cols - set(chunk.columns)\n",
    "                    if missing_cols:\n",
    "                        raise ValueError(f\"Missing columns: {missing_cols}\")\n",
    "                    \n",
    "                    # Track original row count\n",
    "                    original_rows = len(chunk)\n",
    "                    \n",
    "                    # Clean data - Date parsing\n",
    "                    chunk[DATE_COL] = pd.to_datetime(chunk[DATE_COL], errors='coerce')\n",
    "                    date_dropped = chunk[DATE_COL].isna().sum()\n",
    "                    chunk = chunk.dropna(subset=[DATE_COL])\n",
    "                    stats['rows_dropped']['date_parsing'] += date_dropped\n",
    "                    \n",
    "                    # Clean data - Inventory adjustment\n",
    "                    neg_inventory = (chunk['Inventory Level'] < 0).sum()\n",
    "                    chunk['Inventory Level'] = chunk['Inventory Level'].clip(lower=0)\n",
    "                    stats['rows_dropped']['inventory_adjustment'] += neg_inventory\n",
    "                    \n",
    "                    # Clean data - Sales adjustment\n",
    "                    bad_sales = (chunk['Units Sold'] > chunk['Inventory Level']).sum()\n",
    "                    chunk['Units Sold'] = np.where(\n",
    "                        chunk['Units Sold'] > chunk['Inventory Level'],\n",
    "                        chunk['Inventory Level'],\n",
    "                        chunk['Units Sold']\n",
    "                    )\n",
    "                    stats['rows_dropped']['sales_adjustment'] += bad_sales\n",
    "                    \n",
    "                    # Handle numeric overflows\n",
    "                    for col in ['Inventory Level', 'Units Sold', 'Units Ordered']:\n",
    "                        try:\n",
    "                            chunk[col] = pd.to_numeric(chunk[col], downcast='unsigned')\n",
    "                        except:\n",
    "                            pass\n",
    "                    \n",
    "                    chunks.append(chunk)\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    stats['rows_dropped']['chunk_failures'] += len(chunk)\n",
    "                    error_log.append(f\"Chunk {chunk_idx} failed: {str(e)}\")\n",
    "                    continue\n",
    "        \n",
    "        if not chunks:\n",
    "            raise ValueError(\"No valid data chunks were processed\")\n",
    "            \n",
    "        # Combine and finalize\n",
    "        df = pd.concat(chunks, ignore_index=False)\n",
    "        \n",
    "        # Final dtype enforcement and tracking\n",
    "        for col, dtype in DTYPES.items():\n",
    "            if col in df.columns:\n",
    "                try:\n",
    "                    df[col] = df[col].astype(dtype)\n",
    "                except Exception as e:\n",
    "                    error_log.append(f\"Dtype conversion failed for {col}: {str(e)}\")\n",
    "                    # Count rows that would fail conversion\n",
    "                    mask = pd.to_numeric(df[col], errors='coerce').isna()\n",
    "                    stats['rows_dropped']['dtype_conversion'] += mask.sum()\n",
    "                    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "        \n",
    "        df = df.set_index(DATE_COL).sort_index()\n",
    "        stats['final_rows'] = len(df)\n",
    "        \n",
    "        return df, error_log, stats\n",
    "        \n",
    "    except Exception as e:\n",
    "        error_log.append(f\"Fatal import error: {str(e)}\")\n",
    "        return None, error_log, stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1131d2c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-31T17:50:39.922265Z",
     "iopub.status.busy": "2025-05-31T17:50:39.921939Z",
     "iopub.status.idle": "2025-05-31T17:50:40.544183Z",
     "shell.execute_reply": "2025-05-31T17:50:40.542679Z"
    },
    "papermill": {
     "duration": 0.628294,
     "end_time": "2025-05-31T17:50:40.546726",
     "exception": false,
     "start_time": "2025-05-31T17:50:39.918432",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully imported 76,000 rows (out of 76,000 total)\n",
      "\n",
      "Rows dropped during processing:\n",
      "- Date Parsing: 0 rows\n",
      "- Inventory Adjustment: 0 rows\n",
      "- Sales Adjustment: 0 rows\n",
      "- Dtype Conversion: 0 rows\n",
      "- Chunk Failures: 0 rows\n",
      "\n",
      "Sample data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store ID</th>\n",
       "      <th>Product ID</th>\n",
       "      <th>Category</th>\n",
       "      <th>Region</th>\n",
       "      <th>Inventory Level</th>\n",
       "      <th>Units Sold</th>\n",
       "      <th>Units Ordered</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Weather Condition</th>\n",
       "      <th>Promotion</th>\n",
       "      <th>Competitor Pricing</th>\n",
       "      <th>Seasonality</th>\n",
       "      <th>Epidemic</th>\n",
       "      <th>Demand</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-01-01</th>\n",
       "      <td>S001</td>\n",
       "      <td>P0001</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>North</td>\n",
       "      <td>195</td>\n",
       "      <td>102</td>\n",
       "      <td>252</td>\n",
       "      <td>72.720001</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Snowy</td>\n",
       "      <td>False</td>\n",
       "      <td>85.730003</td>\n",
       "      <td>Winter</td>\n",
       "      <td>False</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-01</th>\n",
       "      <td>S001</td>\n",
       "      <td>P0002</td>\n",
       "      <td>Clothing</td>\n",
       "      <td>North</td>\n",
       "      <td>117</td>\n",
       "      <td>117</td>\n",
       "      <td>249</td>\n",
       "      <td>80.160004</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Snowy</td>\n",
       "      <td>True</td>\n",
       "      <td>92.019997</td>\n",
       "      <td>Winter</td>\n",
       "      <td>False</td>\n",
       "      <td>229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-01</th>\n",
       "      <td>S001</td>\n",
       "      <td>P0003</td>\n",
       "      <td>Clothing</td>\n",
       "      <td>North</td>\n",
       "      <td>247</td>\n",
       "      <td>114</td>\n",
       "      <td>612</td>\n",
       "      <td>62.939999</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Snowy</td>\n",
       "      <td>True</td>\n",
       "      <td>60.080002</td>\n",
       "      <td>Winter</td>\n",
       "      <td>False</td>\n",
       "      <td>157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-01</th>\n",
       "      <td>S001</td>\n",
       "      <td>P0004</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>North</td>\n",
       "      <td>139</td>\n",
       "      <td>45</td>\n",
       "      <td>102</td>\n",
       "      <td>87.629997</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Snowy</td>\n",
       "      <td>False</td>\n",
       "      <td>85.190002</td>\n",
       "      <td>Winter</td>\n",
       "      <td>False</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-01</th>\n",
       "      <td>S001</td>\n",
       "      <td>P0005</td>\n",
       "      <td>Groceries</td>\n",
       "      <td>North</td>\n",
       "      <td>152</td>\n",
       "      <td>65</td>\n",
       "      <td>271</td>\n",
       "      <td>54.410000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Snowy</td>\n",
       "      <td>False</td>\n",
       "      <td>51.630001</td>\n",
       "      <td>Winter</td>\n",
       "      <td>False</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Store ID Product ID     Category Region  Inventory Level  \\\n",
       "Date                                                                  \n",
       "2022-01-01     S001      P0001  Electronics  North              195   \n",
       "2022-01-01     S001      P0002     Clothing  North              117   \n",
       "2022-01-01     S001      P0003     Clothing  North              247   \n",
       "2022-01-01     S001      P0004  Electronics  North              139   \n",
       "2022-01-01     S001      P0005    Groceries  North              152   \n",
       "\n",
       "            Units Sold  Units Ordered      Price  Discount Weather Condition  \\\n",
       "Date                                                                           \n",
       "2022-01-01         102            252  72.720001       5.0             Snowy   \n",
       "2022-01-01         117            249  80.160004      15.0             Snowy   \n",
       "2022-01-01         114            612  62.939999      10.0             Snowy   \n",
       "2022-01-01          45            102  87.629997      10.0             Snowy   \n",
       "2022-01-01          65            271  54.410000       0.0             Snowy   \n",
       "\n",
       "            Promotion  Competitor Pricing Seasonality  Epidemic  Demand  \n",
       "Date                                                                     \n",
       "2022-01-01      False           85.730003      Winter     False     115  \n",
       "2022-01-01       True           92.019997      Winter     False     229  \n",
       "2022-01-01       True           60.080002      Winter     False     157  \n",
       "2022-01-01      False           85.190002      Winter     False      52  \n",
       "2022-01-01      False           51.630001      Winter     False      59  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Execute and Display Enhanced Results\n",
    "# Execute the import\n",
    "df, import_errors, import_stats = import_retail_data()\n",
    "\n",
    "# Display results\n",
    "if df is not None:\n",
    "    print(f\"Successfully imported {import_stats['final_rows']:,} rows (out of {import_stats['total_rows']:,} total)\")\n",
    "    print(\"\\nRows dropped during processing:\")\n",
    "    for reason, count in import_stats['rows_dropped'].items():\n",
    "        print(f\"- {reason.replace('_', ' ').title()}: {count:,} rows\")\n",
    "    \n",
    "    print(\"\\nSample data:\")\n",
    "    display(df.head())\n",
    "else:\n",
    "    print(\"Import failed\")\n",
    "\n",
    "if import_errors:\n",
    "    print(\"\\nEncountered warnings/errors:\")\n",
    "    for i, error in enumerate(import_errors, 1):\n",
    "        print(f\"{i}. {error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d492ab2",
   "metadata": {
    "papermill": {
     "duration": 0.002925,
     "end_time": "2025-05-31T17:50:40.553388",
     "exception": false,
     "start_time": "2025-05-31T17:50:40.550463",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **Retail Data Insights Overview**\n",
    "\n",
    "### **1. Investigation Purpose**\n",
    "Systematically evaluate dataset quality to:\n",
    "- Identify integrity issues affecting forecast accuracy  \n",
    "- Uncover demand/sales/inventory patterns  \n",
    "- Guide model selection based on data characteristics  \n",
    "- Document critical metadata for reproducibility  \n",
    "\n",
    "### **2. Key Investigation Areas**\n",
    "\n",
    "#### **A. Data Quality Checks**\n",
    "**Rationale**: Ensure reliable inputs for forecasting  \n",
    "**Targets**:  \n",
    "- **Category labels**: Detect typos/inconsistencies (e.g., \"Electronis\" vs \"Electronics\")  \n",
    "- **Date validity**: Identify gaps or anomalous timestamps  \n",
    "- **Demand outliers**: Flag artificial caps or placeholder values  \n",
    "- **Missing data**: Quantify gaps in key columns (weather/pricing)  \n",
    "\n",
    "#### **B. Dataset Dimensions**\n",
    "**Rationale**: Understand data granularity and coverage  \n",
    "**Metrics**:  \n",
    "| Dimension         | Purpose                                  |\n",
    "|-------------------|-----------------------------------------|\n",
    "| Product Count     | Determine SKU-level vs category forecasting |  \n",
    "| Category Count    | Identify overbroad groupings            |\n",
    "| Date Range        | Assess seasonality coverage            |  \n",
    "| Store/Region      | Evaluate geographical representation   |\n",
    "\n",
    "#### **C. Demand Characteristics**  \n",
    "**Rationale**: Inform model selection  \n",
    "**Analysis**:  \n",
    "- Value range (min/max) to detect censoring  \n",
    "- Zero-demand frequency for intermittent-demand handling  \n",
    "- Epidemic-period variance for shock resilience  \n",
    "\n",
    "### **3. Insights-to-Action Mapping**\n",
    "\n",
    "| Finding                  | Impact                                                         |\n",
    "|--------------------------|----------------------------------------------------------------|\n",
    "| High zero-demand %       | Use Croston's/TSB models                                      |\n",
    "| Regional sales clusters  | Add region dummy variables                                    |  \n",
    "| Epidemic demand spikes   | Implement shock indicator features                           |\n",
    "| Category label typos     | Consolidate labels pre-analysis                               |\n",
    "| Missing weather data     | Impute regionally or exclude weather-dependent models        |\n",
    "\n",
    "### **4. Target Outputs**\n",
    "1. **Data Quality Scorecard**  \n",
    "   - Priority cleaning tasks  \n",
    "   - Model compatibility assessment  \n",
    "2. **Feature Engineering Roadmap**  \n",
    "3. **Model Selection Justification**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b690d5cd",
   "metadata": {
    "papermill": {
     "duration": 0.003035,
     "end_time": "2025-05-31T17:50:40.560217",
     "exception": false,
     "start_time": "2025-05-31T17:50:40.557182",
     "status": "completed"
    },
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1e366304",
   "metadata": {
    "papermill": {
     "duration": 0.003029,
     "end_time": "2025-05-31T17:50:40.566951",
     "exception": false,
     "start_time": "2025-05-31T17:50:40.563922",
     "status": "completed"
    },
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab434b2",
   "metadata": {
    "papermill": {
     "duration": 0.002922,
     "end_time": "2025-05-31T17:50:40.572865",
     "exception": false,
     "start_time": "2025-05-31T17:50:40.569943",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "513bcf0a",
   "metadata": {
    "papermill": {
     "duration": 0.002935,
     "end_time": "2025-05-31T17:50:40.578796",
     "exception": false,
     "start_time": "2025-05-31T17:50:40.575861",
     "status": "completed"
    },
    "tags": []
   },
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 7386309,
     "sourceId": 11895299,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 8.594753,
   "end_time": "2025-05-31T17:50:41.102823",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-05-31T17:50:32.508070",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
